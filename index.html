<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Ting-Hsuan Chen</title>
    <meta name="author" content="Ting-Hsuan Chen">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr style="padding:0px">
          <td style="padding:0px">
            <!-- Header Section -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr style="padding:0px">
                  <td style="padding:2.5%;width:63%;vertical-align:middle">
                    <p class="name" style="text-align: center;">
                      Ting-Hsuan Chen
                    </p>
                    <p>I am currently a master's student in Computer Science at the <a href="https://www.usc.edu/">University of Southern California</a>, advised by Professor <a href="https://yuewang.xyz/">Yue Wang</a>.
                    </p>
                    <p>
                      I have previously worked as an R&D engineer at <a href="https://www.foxconn.com/zh-tw">Foxconn</a> and also served as a research assistant in Professor <a href="https://yulunalexliu.github.io/">Yu-Lun Liu's</a> laboratory at <a href="https://www.nycu.edu.tw/nycu/ch/index">National Yang Ming Chiao Tung University</a>. Currently, I am working at <a href="https://www.bosch.us/">Bosch</a> as a Research Intern focusing on Scene Understanding and Generative AI.
                    </p>
                    <p style="text-align:center">
                      <a href="mailto:kevin953215@gmail.com">Email</a> &nbsp;/&nbsp;
                      <a href="data/Koi-CV.pdf">CV</a> &nbsp;/&nbsp;
                      <a href="https://www.instagram.com/koi_elder?igsh=MXVxcTExOXFhY2Fmaw%3D%3D&utm_source=qr">Instagram</a> &nbsp;/&nbsp;
                      <a href="https://www.linkedin.com/in/tinghsuan69/">LinkedIn</a> &nbsp;/&nbsp;
                      <a href="https://github.com/koi953215/">Github</a>
                    </p>
                  </td>
                  <td style="padding:2.5%;width:40%;max-width:40%">
                    <a href="images/me.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/me.jpg" class="hoverZoomLink"></a>
                  </td>
                </tr>
              </tbody>
            </table>

            <!-- Institution Logos Section -->
            <table style="width:90%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr>
                  <td style="padding:20px;width:100%;vertical-align:middle;text-align:center">
                    <div style="display: flex; justify-content: space-between; align-items: center; flex-wrap: wrap; gap: 20px;">
                      <!-- USC Logo -->
                      <div style="text-align: center; flex: 1; max-width: 160px;">
                        <img src="images/usc-logo.png" alt="USC Logo" style="height: 100px; width: auto; max-width: 100%; object-fit: contain;">
                        <p style="margin: 10px 0 0 0; font-size: 14px; color: #666; font-weight: 500;">USC</p>
                      </div>

                      <!-- Bosch Logo -->
                      <div style="text-align: center; flex: 1; max-width: 160px;">
                        <img src="images/Bosch.jpg" alt="Bosch Logo" style="height: 100px; width: auto; max-width: 100%; object-fit: contain;">
                        <p style="margin: 10px 0 0 0; font-size: 14px; color: #666; font-weight: 500;">Bosch</p>
                      </div>

                      <!-- NYCU Logo -->
                      <div style="text-align: center; flex: 1; max-width: 160px;">
                        <img src="images/nycu.png" alt="NYCU Logo" style="height: 100px; width: auto; max-width: 100%; object-fit: contain;">
                        <p style="margin: 10px 0 0 0; font-size: 14px; color: #666; font-weight: 500;">NYCU</p>
                      </div>

                      <!-- GVL Logo -->
                      <div style="text-align: center; flex: 1; max-width: 160px;">
                        <img src="images/gvl.png" alt="Foxconn Logo" style="height: 100px; width: auto; max-width: 100%; object-fit: contain;">
                        <p style="margin: 10px 0 0 0; font-size: 14px; color: #666; font-weight: 500;">GVL Lab</p>
                      </div>
                    </div>
                  </td>
                </tr>
              </tbody>
            </table>

            <!-- News Section -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr>
                  <td style="padding:20px;width:100%;vertical-align:middle">
                    <h2>News</h2>
                    <div style="max-height: 200px; overflow-y: scroll; border: 1px solid #ccc; padding: 10px;">
                      <table class="table table-sm table-borderless">
                        <tbody>
                          <tr>
                            <th scope="row">Aug, 2025</th>
                            <td style="vertical-align: top; padding-top: 6px;">Contributed a bug fix to NVIDIA Toronto AI Lab's <a href="https://github.com/nv-tlabs/vipe">ViPE</a> project; my patch for multi-view SLAM initialization (<a href="https://github.com/nv-tlabs/vipe/issues/11">Issue #11</a>, <a href="https://github.com/nv-tlabs/vipe/pull/16">PR #16</a>) was merged into the official repository <img src="images/newLOGO_Nvidia.png" width="55" height="25" style="vertical-align: middle;"></td>
                          </tr>
                          <tr><td colspan="2" style="padding: 10px 0;"></td></tr>
                          <tr>
                            <th scope="row">May, 2025</th>
                            <td>Excited to join Bosch as a Scene Understanding/GenAI Research Intern this summerü§ñ</td>
                          </tr>
                          <tr><td colspan="2" style="padding: 10px 0;"></td></tr>
                          <tr>
                            <th scope="row">May, 2025</th>
                            <td>Serve as a reviewer for NeurIPS 2025üìù</td>
                          </tr>
                          <tr><td colspan="2" style="padding: 10px 0;"></td></tr>
                          <tr>
                            <th scope="row">Dec, 2024</th>
                            <td>Received the Viterbi Conference & Research Fund AwardüèÖ</td>
                          </tr>
                          <tr><td colspan="2" style="padding: 10px 0;"></td></tr>
                          <tr>
                            <th scope="row">Oct, 2024</th>
                            <td>Received the NeurIPS 2024 Scholar AwardüèÖ</td>
                          </tr>
                          <tr><td colspan="2" style="padding: 10px 0;"></td></tr>
                          <tr>
                            <th scope="row">Sep, 2024</th>
                            <td>My paper has been accepted by NeurIPS 2024ü•≥</td>
                          </tr>
                          <tr><td colspan="2" style="padding: 10px 0;"></td></tr>
                          <tr>
                            <th scope="row">Aug, 2024</th>
                            <td>Begin my Master's degree at USC in Fall 2024üéì</td>
                          </tr>
                        </tbody>
                      </table>
                    </div>
                  </td>
                </tr>
              </tbody>
            </table>

            <!-- Research Section Title -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr>
                  <td style="padding:20px;width:100%;vertical-align:middle">
                    <h2>Research</h2>
                    <p>
                      I'm interested in computer vision, deep learning, generative AI, 3D reconstruction, autonomous agent, and robotics.
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>
            
            <!-- Research Papers -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <!-- Dino-Diffusion Paper -->
                <tr onmouseout="dino_stop()" onmouseover="dino_start()">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <div class="one">
                      <div class="two" id='dino_image'>
                        <video width=100% height=100% muted autoplay loop>
                          <source src="images/icra26_cross_domain.mp4" type="video/mp4">
                          Your browser does not support the video tag.
                        </video>
                      </div>
                      <img src='images/DINO-DM.png' width="160">
                    </div>
                    <script type="text/javascript">
                      function dino_start() {
                        document.getElementById('dino_image').style.opacity = "1";
                      }
                      function dino_stop() {
                        document.getElementById('dino_image').style.opacity = "0";
                      }
                      dino_stop()
                    </script>
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="https://github.com/ChampagneAndfragrance/Dino_Diffusion_Parking_Official">
                      <span class="papertitle">Dino-Diffusion Modular Designs Bridge the Cross-Domain Gap in Autonomous Parking</span>
                    </a>
                    <br> 
                    <a href="https://champagneandfragrance.github.io/Zixuan_Wu_0.o/">Zixuan Wu</a>,
                    <a href="https://henryzhangzhy.github.io/">Hengyuan Zhang</a>,
                    <strong>Ting-Hsuan Chen</strong>,
                    <a href="https://yuliangguo.github.io/">Yuliang Guo</a>, 
                    <a href="https://avl.ucsd.edu/dfpazr/">David Paz</a>, 
                    <a href="https://scholar.google.com/citations?user=cL4bNBwAAAAJ&hl=zh-TW">Xinyu Huang</a>,
                    <a href="https://www.liu-ren.com/">Liu Ren</a>,
                    <br>
                    <em>under review</em><img src="images/fire-joypixels.gif" width="20" height="20" style="opacity: 0;">
                    <br>
                    <a href="https://arxiv.org/abs/2510.20335">arXiv</a>
                    /
                    <a href="https://github.com/ChampagneAndfragrance/Dino_Diffusion_Parking_Official">code</a>
                    <p style="margin: 10px 0;">
                    <!-- <a href="https://github.com/koi953215/NaRCan/stargazers">
                      <img src="https://img.shields.io/github/stars/koi953215/NaRCan?style=social" alt="GitHub stars">
                    </a> -->
                    </p>
                    A modular parking pipeline combining DINOv2 visual foundation models with diffusion-based planning for robust zero-shot transfer across weather and lighting conditions. Achieves 90%+ success rate in cross-domain tests and shows promising sim-to-real transfer.
                  </td>
                </tr>

                <!-- MoonSim Paper -->
                <tr onmouseout="moonsim_stop()" onmouseover="moonsim_start()">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <div class="one">
                      <div class="two" id='moonsim_image'>
                        <video width=100% height=100% muted autoplay loop>
                          <source src="images/moonsim_teaser.mp4" type="video/mp4">
                          Your browser does not support the video tag.
                        </video>
                      </div>
                      <img src='images/moon_teaser.jpg' width="160">
                    </div>
                    <script type="text/javascript">
                      function moonsim_start() {
                        document.getElementById('moonsim_image').style.opacity = "1";
                      }
                      function moonsim_stop() {
                        document.getElementById('moonsim_image').style.opacity = "0";
                      }
                      moonsim_stop()
                    </script>
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="https://anonymousi079j.github.io/moonsim/">
                      <span class="papertitle">MoonSim: A Photorealistic Lunar Environment Simulator</span>
                    </a>
                    <br>
                    <strong>Ting-Hsuan Chen*</strong>, 
                    <a href="https://henghuib.github.io/">Henghui Bao*</a>,
                    <a href="https://ziyc.github.io/">Ziyu Chen*</a>,
                    <a href="https://github.com/louhz">Haozhe Lou</a>, 
                    <a href="https://www.episodeyang.com/">Ge Yang</a>, 
                    <a href="https://zhiwenfan.github.io/">Zhiwen Fan</a>,
                    <a href="https://profiles.stanford.edu/marco-pavone">Marco Pavone</a>,
                    <a href="https://yuewang.xyz/">Yue Wang</a>,
                    <br>
                    <em>under review</em><img src="images/fire-joypixels.gif" width="20" height="20" style="opacity: 0;">
                    <br>
                    <a href="https://anonymousi079j.github.io/moonsim/">project page</a>
                    <p></p>
                    <p>
                      MoonSim is a photo-realistic lunar scene simulator that incorporates Unreal Engine for high-quality lunar images with realistic lighting and shadows and MuJoCo for physics simulation, supporting diverse locomotion and navigation tasks.
                    </p>
                  </td>
                </tr>

                <!-- NaRCan Paper -->
                <tr onmouseout="narcan_stop()" onmouseover="narcan_start()" bgcolor="#ffffd0">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <div class="one">
                      <div class="two" id='bear_image'>
                        <video width=100% height=100% muted autoplay loop>
                          <source src="images/bear_separate=4.mp4" type="video/mp4">
                          Your browser does not support the video tag.
                        </video>
                      </div>
                      <img src='images/bear_canonical.png' width="160">
                    </div>
                    <script type="text/javascript">
                      function narcan_start() {
                        document.getElementById('bear_image').style.opacity = "1";
                      }
                      function narcan_stop() {
                        document.getElementById('bear_image').style.opacity = "0";
                      }
                      narcan_stop()
                    </script>
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="https://koi953215.github.io/NaRCan_page/">
                      <span class="papertitle">NaRCan: Natural Refined Canonical Image with Integration of Diffusion Prior for Video Editing</span>
                    </a>
                    <br>
                    <strong>Ting-Hsuan Chen</strong>, 
                    <a href="https://jiewenchan.github.io/">Jiewen Chan</a>,
                    <a href="https://github.com/00757039">Hau-Shiang Shiu</a>,
                    <a href="https://github.com/alexyen1006">Shih Han Yen</a>, 
                    <a href="https://jimmycv07.github.io/">Changhan Yeh</a>, 
                    <a href="https://yulunalexliu.github.io/">Yu-Lun Liu</a>,
                    <br>
                    <em>NeurIPS</em>, 2024 <img src="images/fire-joypixels.gif" width="20" height="20">
                    <br>
                    <a href="https://koi953215.github.io/NaRCan_page/">project page</a>
                    /
                    <a href="https://arxiv.org/abs/2406.06523">arXiv</a>
                    /
                    <a href="https://github.com/koi953215/NaRCan">code</a>
                    /
                    <a href="https://huggingface.co/spaces/Koi953215/NaRCan_demo">demo</a>
                    <p style="margin: 10px 0;">
                    <a href="https://github.com/koi953215/NaRCan/stargazers">
                      <img src="https://img.shields.io/github/stars/koi953215/NaRCan?style=social" alt="GitHub stars">
                    </a>
                    </p>
                    NaRCan, a video editing framework, integrates a hybrid deformation field network with diffusion priors to address the challenge of maintaining the canonical image as a natural image.
                  </td>
                </tr>    

                <!-- DiffIR2VR Paper -->
                <tr onmouseout="DiffIR2VR_stop()" onmouseover="DiffIR2VR_start()">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <div class="one">
                      <div class="two" id='train_image'>
                        <video width=100% height=100% muted autoplay loop>
                          <source src="images/denoise_train.mp4" type="video/mp4">
                          Your browser does not support the video tag.
                        </video>
                      </div>
                      <img src='images/lq_train.png' width="160">
                    </div>
                    <script type="text/javascript">
                      function DiffIR2VR_start() {
                        document.getElementById('train_image').style.opacity = "1";
                      }
                      function DiffIR2VR_stop() {
                        document.getElementById('train_image').style.opacity = "0";
                      }
                      DiffIR2VR_stop()
                    </script>
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="https://jimmycv07.github.io/DiffIR2VR_web/">
                      <span class="papertitle">DiffIR2VR-Zero: Zero-Shot Video Restoration with Diffusion-based Image Restoration Models</span>
                    </a>
                    <br>
                    <a href="https://jimmycv07.github.io/">Changhan Yeh</a>,
                    <a href="https://linjohnss.github.io/">Chin-Yang Lin</a>, 
                    <a href="https://lightchaserx.github.io/">Zhixiang Wang</a>,
                    <a href="https://chiweihsiao.github.io/">Chi-Wei Hsiao</a>,
                    <strong>Ting-Hsuan Chen</strong>,  
                    <a href="https://yulunalexliu.github.io/">Yu-Lun Liu</a>,
                    <br>
                    <em>arXiv</em>, 2024 <img src="images/fire-joypixels.gif" width="20" height="20" style="opacity: 0;">
                    <br>
                    <a href="https://jimmycv07.github.io/DiffIR2VR_web/">project page</a>
                    /
                    <a href="https://arxiv.org/abs/2407.01519">arXiv</a>
                    /
                    <a href="https://github.com/jimmycv07/DiffIR2VR-Zero">code</a>
                    /
                    <a href="https://huggingface.co/spaces/Koi953215/DiffIR2VR">demo</a>
                    <p style="margin: 10px 0;">
                    <a href="https://github.com/jimmycv07/DiffIR2VR-Zero/stargazers">
                      <img src="https://img.shields.io/github/stars/jimmycv07/DiffIR2VR-Zero?style=social" alt="GitHub stars">
                    </a>
                    </p>
                    This paper introduces a novel zero-shot video restoration method using pre-trained image restoration diffusion models, achieving excellent performance across diverse datasets and extreme video degradations.
                  </td>
                </tr>
              </tbody>
            </table>

            <!-- Project Section Title -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr>
                  <td style="padding:20px;width:100%;vertical-align:middle">
                    <h2>Project</h2>
                  </td>
                </tr>
              </tbody>
            </table>
            
            <!-- Project Items -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <!-- DreamMesh Project -->
                <tr onmouseout="dreammesh_stop()" onmouseover="dreammesh_start()">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <div class="one">
                      <div class="two" id='dreammesh_image'>
                        <video width=100% height=100% muted autoplay loop>
                          <source src="images/DreamMesh.mp4" type="video/mp4">
                          Your browser does not support the video tag.
                        </video>
                      </div>
                      <img src='images/DreamMesh.png' width="160">
                    </div>
                    <script type="text/javascript">
                      function dreammesh_start() {
                        document.getElementById('dreammesh_image').style.opacity = "1";
                      }
                      function dreammesh_stop() {
                        document.getElementById('dreammesh_image').style.opacity = "0";
                      }
                      dreammesh_stop()
                    </script>
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="https://github.com/koi953215/DreamMesh">
                      <span class="papertitle">DreamMesh</span>
                    </a>
                    <br>
                    <strong>Ting-Hsuan Chen</strong>,
                    <a href="https://cameronosmith.github.io/">Cameron Smith</a>,
                    <a href="https://pointscoder.github.io/">Jiageng Mao</a>,
                    <a href="https://dw1209.github.io/">Daniel Wang</a>,
                    <br>
                    <em>github</em>, 2025
                    <br>
                    <p></p>
                    <p>
                      A Blender plugin that transforms text or image inputs into complete 3D scenes with rigged objects, realistic AI-generated backgrounds, and intelligent object placement, all powered by generative AI.
                    </p>
                  </td>
                </tr>
                
                <!-- GPU-SplineTransformer Project -->
                <tr bgcolor="#ffffd0">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <div class="one">
                      <img src='images/Speedup.png' width="160">
                    </div>
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="https://github.com/koi953215/GPU-SplineTransformer">
                      <span class="papertitle">GPU-SplineTransformer</span>
                    </a>
                    <br>
                    <strong>Ting-Hsuan Chen</strong>
                    <br>
                    <em>github</em>, 2022
                    <br>
                    <p></p>
                    <p>
                      My GPU-Optimized SplineTransformer significantly accelerates the conversion of large data arrays into B-spline bases by leveraging GPU power. This innovation outperforms traditional CPU-based solutions, offering enhanced speed and efficiency for your data processing needs.
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>
            <!-- Patent Section Title -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr>
                  <td style="padding:20px;width:100%;vertical-align:middle">
                    <h2>Patent</h2>
                  </td>
                </tr>
              </tbody>
            </table>

            <!-- Patent Items -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <div class="one">
                      <img src='images/BLOG_TIPO.jpg' width="160">
                    </div>
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <span class="papertitle">Data Analysis Method, Apparatus, Electronic Device and Storage Medium</span>
                    <br>
                    <strong>Ting-Hsuan Chen</strong>
                    <br>
                    <em>TW113141155</em>, 2024
                    <br>
                    <p></p>
                    <p>
                      A data analysis method based on feature waveform analysis, improving the accuracy of feature waveform recognition through convolution and segmentation operations. This patent is currently in the confidential stage and is expected to be declassified in 2026.
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>
            <!-- Professional Experience Section Title -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr>
                  <td style="padding:20px;width:100%;vertical-align:middle">
                    <h2>Professional Experience</h2>
                  </td>
                </tr>
              </tbody>
            </table>

            <!-- Professional Experience Items -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <!-- USC Geometry, Vision, and Learning Lab -->
                <tr bgcolor="#ffffd0">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <div class="one">
                      <img src='images/gvl.png' width="160">
                    </div>
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <span class="papertitle">MS Student & Research Assistant</span>
                    <br>
                    <a href="https://usc-gvl.github.io/">USC Geometry, Vision, and Learning Lab</a>, Los Angeles, California, USA
                    <br>
                    <em>Aug 2024 - Present</em>
                    <br>
                    <p></p>
                    <p>
                      At USC's Geometry, Vision, and Learning Lab, I explore diffusion models as priors to improve 3D reconstruction quality and enable 3D scene editing. I also work on autonomous web agents and develop physics-based robotics simulators to bridge the sim-to-real gap.
                    </p>
                  </td>
                </tr>

                <!-- Bosch Internship -->
                <tr bgcolor="#ffffd0">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <div class="one">
                      <img src='images/Bosch.jpg' width="160">
                    </div>
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <span class="papertitle">Scene Understanding/GenAI Research Intern</span>
                    <br>
                    <a href="https://www.bosch-ai.com/">Bosch Center for Artificial Intelligence</a>, Sunnyvale, California, USA
                    <br>
                    <em>May 2025 - Present</em>
                    <br>
                    <p></p>
                    <p>
                      Working on cutting-edge research in scene understanding and generative AI technologies. Collaborating with the research team to develop innovative solutions for computer vision applications.
                    </p>
                  </td>
                </tr>

                <!-- NYCU Computational Photography Lab -->
                <tr bgcolor="#ffffd0">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <div class="one">
                      <img src='images/nycu.png' width="160">
                    </div>
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <span class="papertitle">Research Assistant</span>
                    <br>
                    <a href="https://yulunalexliu.github.io/">NYCU Computational Photography Lab</a>, Hsinchu, Taiwan
                    <br>
                    <em>Jan 2024 - June 2024</em>
                    <br>
                    <p></p>
                    <p>
                      At the NYCU Computational Photography Lab, my primary research focused on diffusion models. During this period, I successfully published a paper as the first author, which was accepted at NeurIPS 2024. Additionally, I participated in industry-academia collaborations with Nvidia and MediaTek, applying research findings to real-world industry challenges.
                    </p>
                  </td>
                </tr>
                
                <!-- Foxconn Experience (combined) -->
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <div class="one">
                      <img src='images/Foxconn.png' width="160">
                    </div>
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <span class="papertitle">R&D Engineer</span>
                    <br>
                    <a href="https://www.foxconn.com/">Foxconn, Hon Hai Precision Industry</a>, Taipei, Taiwan
                    <br>
                    <em>July 2023 - Dec 2023</em>
                    <br>
                    <p></p>
                    <p>
                      At Foxconn, I developed the company's first patented ECG waveform recognition system by integrating AI, computer vision, and signal processing techniques. I also mentored new interns and represented the company in various medical conferences. Previously, I built an AI-based data cleansing and classification system, along with essential APIs using Django for medical data processing.
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>
            <!-- Awards Section Title -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr>
                  <td style="padding:20px;width:100%;vertical-align:middle">
                    <h2>Awards & Recognitions</h2>
                  </td>
                </tr>
              </tbody>
            </table>

            <!-- Awards Content -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr>
                  <td style="padding:20px;width:100%;vertical-align:middle">
                    <ul style="margin-top:0; padding-left:20px;">
                      <li><strong>Dec. 2024</strong> - Viterbi Conference & Research Fund Award, USC</li>
                      <li><strong>Oct. 2024</strong> - NeurIPS 2024 Scholar Award</li>
                      <li><strong>Jun. 2023</strong> - Valedictorian, NCHU</li>
                      <li><strong>Jun. 2023</strong> - Elected to The Phi Tau Phi Scholastic Honor Society (Top 1 graduate & College of Science representative)<br><span style="color:red;">An elite academic honor society admitting only the top 1% of graduates across Taiwan</span></li>
                      <li><strong>Apr. 2023</strong> - Golden Key</li>
                      <li><strong>2020-2022</strong> - Presidential Award (6 times)</li>
                      <li><strong>2020-2022</strong> - Dean's List (2 times)</li>
                      <li><strong>Nov. 2021</strong> - Ching-O Award</li>
                      <li><strong>Nov. 2021</strong> - Outstanding Academic Achievement Award</li>
                      <li><strong>Jun. 2021</strong> - Professor Kuo Jin-Bin Scholarship</li>
                      <li><strong>Oct. 2020</strong> - Building Futures Foundation Scholarship</li>
                      <li><strong>Oct. 2020</strong> - Outstanding Academic Achievement Award</li>
                      <li><strong>Jul. 2020</strong> - Certificate of Excellent Performance</li>
                    </ul>
                  </td>
                </tr>
              </tbody>
            </table>
          </td>
        </tr>
      </tbody>
    </table>
  </body>
</html>